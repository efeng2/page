# 聚类分析
2023-10-11  

## 无监督学习 (Unsupervised Learning)  
- 数据无标签  

无监督学习是指模型在没有标签指导的情况下，自主发现数据内在结构和模式的学习方式。其核心目标是探索数据的底层分布特征，聚类等技术被用于将相似数据点自动分组。  

## 有监督学习 (Supervised Learning)  
- 输入数据带有已知标签  

有监督学习通过已标注数据（每个样本都有对应的输出标签）训练模型，目标是建立从输入到输出的映射关系，从而对新数据做出准确预测。  

### 典型应用：  
- 基于标注数据训练模型判断邮件是否为垃圾邮件  

## 聚类分析 (Clustering)  
- 发现数据簇并将样本划分到特定簇中  

聚类是一种无监督学习方法，旨在将数据集划分为若干相似数据点的集合（簇）。其核心假设是：同一簇内的数据点相似度高于不同簇间的相似度。  

## 聚类中心 (Centroid)  
- 表征簇的中心位置  

在聚类中，中心点代表簇内所有数据点的均值位置，是描述簇特征的关键指标。  

## k-means++算法  
- 通过最大化初始中心点间距的初始化方法  

k-means++是对传统k-means算法的改进，通过选择相互远离的点作为初始中心，有效避免随机初始化导致的局部最优问题。  

### 优势说明：  
- 相比随机初始化，k-means++选择的初始中心点间距更大，显著提升聚类质量  

## 坐标下降法 (Coordinate Descent)  
- 每步迭代中，步骤1/2保证异质性递减或不变  

这种优化方法通过交替执行两个步骤来最小化目标函数：1）将点分配到最近中心点 2）重新计算中心点位置。每次迭代都确保簇内距离平方和减小或保持不变。  

## 混合模型 (Mixture Models)  
- 将每个簇建模为独立概率分布并学习参数，支持软分配（概率隶属）  

混合模型假设数据由多个概率分布混合生成，每个簇对应一个分布。与硬聚类不同，它允许数据点以不同概率属于多个簇，提供更细粒度的聚类结果。  

## 层次聚类 (Hierarchical Clustering)  
- 基于树状图（Dendrogram）的可视化方法  

层次聚类通过构建簇的层次结构（可可视化展示为树状图）进行分析，主要分为两种方法：  

### 分裂式 (Divisive)  
- 自上而下，从单个大簇开始递归分裂  

从所有数据点组成的大簇出发，持续将最"异构"的簇分裂为更小的同质子簇。  

### 聚合式 (Agglomerative)  
- 自下而上，从单点簇开始逐层合并  

初始每个数据点作为独立簇，基于簇间距离度量，迭代合并最近邻簇直至形成单一簇。  

## 树状图解析 (Dendrogram)  
- x轴显示特定顺序排列的数据点  
- y轴表示簇间距离  
- 节点高度反映簇合并时的最小距离  

树状图直观展示层次聚类的全过程，通过观察不同高度上的簇合并情况，可辅助确定最佳聚类数量。节点高度越高，说明合并时的簇间差异越大。  

注：  
1. 专业术语采用中英对照格式（如"k-means++算法"）  
2. 核心算法通过步骤分解说明（如坐标下降法的交替优化过程）  
3. 可视化方法附加解读指南（如树状图坐标含义）  
4. 对比分析不同方法特性（如硬聚类vs混合模型的软分配）  
5. 关键改进算法说明技术优势（如k-means++的初始化策略）