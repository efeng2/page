# 马尔可夫决策过程
2025-03-03  

## 马尔可夫模型 (Markov Models)  

马尔可夫模型通过将时间或空间因素纳入概率模型，帮助分析序列数据。  

### 典型应用  
- 语音识别 (Speech recognition)  
- 机器人定位 (Robot localization)  
- 用户注意力追踪 (User attention tracking)  
- 医疗监测 (Medical monitoring)  

在时刻$t$，系统状态$S_t$由以下关系决定：  

$$
P(S_1) P(S_t | S_{t-1})
$$

核心特征：  
- 转移概率 (Transition probabilities)：定义状态演化规律  
- 稳态假设 (Stationarity assumption)：概率不随时间改变  
- 无动作选择（区别于MDPs）  

### 联合概率分布  

$$
P(S_1, S_2, ..., S_T) = P(S_1) \prod_{t=2}^{T} P(S_t | S_{t-1})
$$

---

## 马尔可夫决策过程 (MDPs)  

MDPs在马尔可夫模型基础上引入动作和奖励机制：  

- 状态集合 $ s \in S $（如：机器人位置）  
- 动作集合 $ a \in A $（如：车辆驾驶操作）  
- 转移函数 $ T(s, a, s') $（如：交通状况影响到达时间）  
- 奖励函数 $ R(s, a, s') $（如：提前到达奖励+20）  
- 策略 $ \pi(s) \to a $：状态到动作的映射  
- 价值函数 $ V_{\pi}(s) $：衡量状态的长期收益  

### 核心计算  

状态价值 (Value(s)) = 经过若干转移后可获奖励  

考虑折扣因子时：  
$G_t = R_{t+1} + \gamma R_{t+2} + \gamma^2 R_{t+3}$  

贝尔曼方程与值迭代求解最优路径方法详见：  
[链接](http://github.efeng2.io/page/cn/blog/AI%20and%20ML%20Algorithms/Markov%20Models/Markov%20Decision%20Processes)  
