# 回归分析与优化方法（Regression）
2023-10-11  

回归分析是机器学习和统计学中用于建模变量关系的基础技术，梯度下降和交叉验证等优化方法可有效提升模型性能。  

## 回归类型  

### 线性回归 (Linear Regression)  
- 通过最小化残差平方和寻找最佳拟合直线  
- 假设输入特征与目标变量呈线性关系  

### 岭回归 (Ridge Regression/L2正则化)  
- 在损失函数中添加L2惩罚项以抑制系数过大  
- 通过系数收缩防止过拟合，但不会将系数归零  

### LASSO回归 (LASSO Regression/L1正则化)  
- 采用L1惩罚项，可使部分系数精确归零  
- 具有特征选择功能，仅保留最重要特征  
- 正则化参数(\(\lambda\))越大，系数归零越多，模型越简单但可能欠拟合  

## 过拟合与欠拟合  

- **过拟合**：  
  - 模型过于复杂（如高阶多项式回归）  
  - 低偏差高方差——训练集表现优异但泛化能力差  

- **欠拟合**：  
  - 模型过于简单（如用线性回归处理非线性问题）  
  - 高偏差低方差——无法捕捉数据内在规律  

## 分类相关概念  

- **简单阈值分类器**：  
  - 根据设定阈值直接输出正/负判定结果  

- **线性分类器**：  
  - 为输入特征分配权重，基于加权求和进行决策  

- **决策边界**：  
  - 分类问题中区分不同类别的分界线  

- **泛化误差**：  
  - 训练误差与验证误差的差异，反映模型在新数据上的表现  

## 优化技术  

### 梯度下降 (Gradient Descent)  
- 通过最小化损失函数寻找最优参数的迭代算法  
- 沿梯度最陡下降方向逐步更新参数  

### 交叉验证 (Cross-Validation)  
- 将数据集划分为k个子集的模型评估方法  
- 每次使用1个子集验证，其余训练，共构建k个模型  
- 可有效评估不同复杂度下的模型表现  
