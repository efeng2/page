# 深度学习与大语言模型中的数学原理  
2025-03-09  

前置知识：[感知机](http://github.efeng2.io/page/blog/AI%20and%20ML%20Algorithms/Markov%20Models/Preceptrons)  

## 前馈神经网络 (FeedForward Neural Network)  

## 隐藏层节点输入激活  

### Sigmoid激活函数  
- 连续且可微分  
- 当输入值绝对值增大时，其导数趋近于零，可能导致梯度下降算法需要很长时间才能收敛  

数学表达式：  
$g_1(h) = \frac{1}{(1+e^h)}$  

### 线性整流单元(ReLU)  
- 连续且次可微分  
- 计算高效，缓解梯度消失问题  

数学表达式：  
$g_3(h) = max(0,h)$  

### Softmax函数  
- 用于计算词语的联合概率分布，在生成式大语言模型中预测下一个最可能的词元  
- 输出值域为[0,1]区间  
- 将原始分数转换为概率分布  

<!-- 更多关于大语言模型中Softmax的应用详见：[N层神经网络](N-Layer Neural Network)   -->